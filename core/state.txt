# FIXED State Management - LangGraph 0.4.8 (June 2025)
# CRITICAL FIXES: Proper message validation, tool call handling, and modern patterns

from typing import Annotated, List, Dict, Any, Optional, Union, Sequence
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage
from langgraph.graph.message import MessagesState, add_messages
from langgraph.managed import RemainingSteps  # ✅ CRITICAL FIX: Add this import
from dataclasses import dataclass, field
from enum import Enum
import logging
import time

logger = logging.getLogger("state")

class AgentType(Enum):
    """Available agent types in the system"""
    CHAT = "chat"
    CODER = "coder"
    WEB = "web"
    SUPERVISOR = "supervisor"

@dataclass
class ThinkingState:
    """Real-time thinking state for GUI display"""
    active_agent: AgentType
    current_task: str
    progress: float
    details: str

def validate_and_filter_messages_v2(messages: List[BaseMessage]) -> List[BaseMessage]:
    """
    ✅ ENHANCED: Filter out messages with empty content for Anthropic compatibility
    Handles tool calls, tool messages, and Anthropic's strict requirements
    """
    if not messages:
        return []
    
    validated = []
    
    for i, message in enumerate(messages):
        should_keep = False
        
        # Handle AIMessage with tool calls (these can have empty content)
        if isinstance(message, AIMessage):
            # Check if this is a tool call message
            has_tool_calls = hasattr(message, 'tool_calls') and message.tool_calls
            
            if has_tool_calls:
                # Tool call messages are valid even with empty content
                should_keep = True
                logger.debug(f"Keeping AIMessage with tool calls at position {i}")
            else:
                # Regular AI message - must have content
                content = getattr(message, 'content', '')
                should_keep = bool(content and content.strip())
        
        # Handle ToolMessage (always keep if properly formed)
        elif isinstance(message, ToolMessage):
            # Tool messages should have content and tool_call_id
            has_content = bool(getattr(message, 'content', ''))
            has_tool_call_id = bool(getattr(message, 'tool_call_id', ''))
            should_keep = has_content and has_tool_call_id
            
        # Handle HumanMessage and SystemMessage (must have content)
        else:
            content = getattr(message, 'content', '')
            if isinstance(content, str):
                should_keep = bool(content.strip())
            elif isinstance(content, list):
                should_keep = any(
                    item.get('text', '').strip() if isinstance(item, dict) 
                    else str(item).strip() 
                    for item in content
                )
            else:
                should_keep = bool(content)
        
        if should_keep:
            validated.append(message)
        else:
            logger.info(f"Filtered out empty message at position {i}: {type(message).__name__}")
    
    # ✅ CRITICAL: Ensure we don't end with an empty assistant message
    # unless it's a tool call message
    if validated and isinstance(validated[-1], AIMessage):
        last_msg = validated[-1]
        has_tool_calls = hasattr(last_msg, 'tool_calls') and last_msg.tool_calls
        has_content = bool(getattr(last_msg, 'content', '').strip())
        
        if not has_tool_calls and not has_content:
            logger.warning("Removing final empty AIMessage without tool calls")
            validated.pop()
    
    return validated


# ✅ FIXED: Modern AssistantState for LangGraph 0.4.8
@dataclass
class AssistantState(MessagesState):
    """
    ✅ FIXED: Modern LangGraph 0.4.8 state using MessagesState pattern.
    CRITICAL IMPROVEMENTS for June 2025:
    - Added required remaining_steps field for supervisor compatibility
    - Fully compatible with LangGraph 0.4.8 state_schema requirements
    - Uses proper type annotations for 0.4.8
    - Inherits from MessagesState for built-in message handling
    - Simplified field definitions without redundant message handling
    - Proper initialization with mutable field defaults
    """
    # MessagesState already provides:
    # messages: Annotated[Sequence[BaseMessage], add_messages]
    
    # ✅ CRITICAL FIX: Add required remaining_steps field for supervisor
    remaining_steps: RemainingSteps = 25  # Default to 25 steps

    # ✅ Agent and session management
    current_agent: str = ""
    thinking_state: Optional[ThinkingState] = None
    session_id: str = ""
    user_id: str = "default_user"

    # ✅ Agent-specific context
    code_context: Dict[str, Any] = field(default_factory=dict)
    web_results: List[Dict[str, Any]] = field(default_factory=list)

    # ✅ Human-in-the-loop control (enhanced for 0.4.8)
    requires_approval: bool = False
    approval_context: Dict[str, Any] = field(default_factory=dict)
    pending_human_input: Optional[str] = None
    interrupt_reason: Optional[str] = None  # New in 0.4.8

    # ✅ File and output management
    temp_files: List[str] = field(default_factory=list)
    saved_files: List[str] = field(default_factory=list)
    output_content: str = ""
    output_type: str = "text"

    # ✅ Enhanced memory management for 0.4.8
    max_messages: int = 50
    memory_strategy: str = "smart_trim"  # Updated strategy
    message_budget: int = 4000  # Token budget for messages

    # ✅ Performance and monitoring
    token_usage: Dict[str, int] = field(default_factory=dict)
    processing_time: float = 0.0
    agent_execution_count: Dict[str, int] = field(default_factory=dict)

    # ✅ Modern LangGraph 0.4.8 features
    checkpoint_namespace: Optional[str] = None
    subgraph_context: Dict[str, Any] = field(default_factory=dict)
    stream_mode: str = "values"  # Default stream mode

    def __post_init__(self):
        """Initialize computed fields after creation"""
        if not self.session_id:
            self.session_id = f"session_{int(time.time())}"

        # Ensure agent execution count is initialized
        for agent_type in AgentType:
            if agent_type.value not in self.agent_execution_count:
                self.agent_execution_count[agent_type.value] = 0

# ✅ CRITICAL FIX: Fix smart_trim_messages_v2 to work with proper state objects
# ✅ CRITICAL FIX: Fix smart_trim_messages_v2 to work with proper state objects

def smart_trim_messages_v2(
    state: Union[AssistantState, Dict[str, Any]],
    max_tokens: int = 4000,
    preserve_system: bool = True,
    preserve_recent_tools: bool = True
) -> Dict[str, Any]:
    """
    ✅ FIXED: Smart message trimming for LangGraph 0.4.8 with enhanced features
    """
    try:
        from langchain_core.messages.utils import trim_messages
        
        # ✅ Always treat state as dictionary
        current_messages = state.get("messages", [])
        
        if not current_messages:
            return {"messages": [HumanMessage(content="Hello")]}
        
        # ✅ FIXED: Single trim_messages call with fallback handling
        try:
            # Try modern trim_messages with full parameters
            trimmed = trim_messages(
                messages=current_messages,
                max_tokens=max_tokens,
                strategy="last",
                token_counter=lambda msgs: sum(len(str(getattr(m, 'content', ''))) // 4 for m in msgs)
            )
        except TypeError as e:
            # Fallback for different trim_messages signatures
            logger.warning(f"trim_messages parameter error: {e}, using simple fallback")
            trimmed = trim_messages(
                messages=current_messages,
                max_tokens=max_tokens,
                strategy="last"
            )
        
        # ✅ CRITICAL: Validate after trimming
        validated = validate_and_filter_messages_v2(trimmed)
        logger.info(f"Smart message trimming v2: {len(current_messages)} -> {len(trimmed)} -> {len(validated)}")
        
        return {"messages": validated}
        
    except Exception as e:
        logger.error(f"Error in smart_trim_messages_v2: {e}")
        # Enhanced fallback strategy
        current_messages = state.get("messages", [])
        
        if current_messages:
            # Keep recent messages and validate
            recent = current_messages[-15:]
            validated = validate_and_filter_messages_v2(recent)
            return {"messages": validated}
        else:
            return {"messages": [HumanMessage(content="Hello")]}

def create_optimized_state(
    session_id: str = "",
    user_id: str = "default",
    initial_context: Optional[Dict[str, Any]] = None
) -> AssistantState:
    """
    ✅ FIXED: Create proper AssistantState instance
    """
    import time
    
    # Base state data
    state_data = {
        "session_id": session_id or f"session_{int(time.time())}",
        "user_id": user_id,
        "messages": [],
        "current_agent": "",
        "stream_mode": "values",
        "message_budget": 4000,
        "memory_strategy": "smart_trim",
        "remaining_steps": 25
    }
    
    # Apply initial context if provided
    if initial_context:
        # Handle messages separately to ensure proper validation
        if "messages" in initial_context:
            validated_messages = validate_and_filter_messages_v2(initial_context["messages"])
            state_data["messages"] = validated_messages
            # Remove from initial_context to avoid double-setting
            initial_context = {k: v for k, v in initial_context.items() if k != "messages"}
        
        state_data.update(initial_context)
    
    # ✅ Create proper AssistantState instance
    return AssistantState(**state_data)


# ✅ CRITICAL FIX: Fix update_state_with_validation to properly handle state objects
def update_state_with_validation(
    current_state: AssistantState,
    updates: Dict[str, Any]
) -> AssistantState:
    """
    ✅ FIXED: Update state with enhanced validation for 0.4.8
    """
    try:
        # Convert current state to dict for updates
        current_state_dict = {k: getattr(current_state, k) for k in current_state.__annotations__}
        
        # Update with new values
        new_state_data = current_state_dict.copy()
        new_state_data.update(updates)

        # ✅ Validate messages if they were updated
        if "messages" in updates:
            new_state_data["messages"] = validate_and_filter_messages_v2(updates["messages"])

        # ✅ Update agent execution count if agent changed
        if "current_agent" in updates and updates["current_agent"]:
            agent_name = updates["current_agent"]
            if agent_name in new_state_data.get("agent_execution_count", {}):
                new_state_data["agent_execution_count"][agent_name] += 1

        # ✅ CRITICAL FIX: Create a proper AssistantState instance
        return AssistantState(**new_state_data)
    except Exception as e:
        logger.error(f"Error updating state: {e}")
        return current_state

# ✅ Modern reducers for LangGraph 0.4.8
def enhanced_message_reducer(
    current: Sequence[BaseMessage],
    new: Union[BaseMessage, Sequence[BaseMessage]]
) -> Sequence[BaseMessage]:
    """
    ✅ FIXED: Enhanced message reducer for LangGraph 0.4.8
    """
    if isinstance(new, BaseMessage):
        new_messages = [new]
    else:
        new_messages = list(new)

    updated_messages = list(current) + new_messages
    return validate_and_filter_messages_v2(updated_messages)

# ✅ Backward compatibility
validate_and_filter_messages = validate_and_filter_messages_v2
smart_trim_messages = smart_trim_messages_v2
create_empty_state = create_optimized_state
update_state_safely = update_state_with_validation

# Legacy compatibility
MorteyState = AssistantState